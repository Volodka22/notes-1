# Contents

[Lecture 1. rvalue-ссылки](#lecture-1-rvalue-ссылки)

[Lecture 2. rvalue-ссылки](#lecture-2-rvalue-ссылки)

[Lecture 3. Intrusive контейнеры](#lecture-3-intrusive-контейнеры)

[Lecture 4. shared_ptr](#lecture-4-shared_ptr)

[Lecture 5. lambda](#lecture-5-lambda)

[Lecture 6. std::function](#lecture-6-std-function)

[Lecture 7. Сигналы](#lecture-7-сигналы)

[Lecture 8. Обработка ошибок](#lecture-8-обработка-ошибок)

[Lecture 9. Кодировки](#lecture-9-кодировки)

[Lecture 10. Концепты 1](#lecture-10-концепты-1)

[Lecture 11. Концепты 2](#lecture-11-концепты-2)

[Lecture 12. Ranges](#lecture-12-ranges)

[Lecture 13. Многопоточность 1](#lecture-13-многопоточность-1)

[Lecture 14. Многопоточность 2](#lecture-14-многопоточность-2)





# Lecture 1. rvalue-ссылки

+: позволяет уменьшать число копирований

А когда они вообще возникают?
1. При передаче параметров

    ```
        struct mytype {
            ...
        }
        void f(mytype); 
        mytype g();
        
        f(g());  // не будет вызван конструктор копирования mytype, т.к. g() - это rvalue (см. дальше)
    ```
    Во что вообще транслируется вызов при передачи параметров?
    ```
    void f(mytype r) {
        r.a = 42;
    }
    
    mytype y;
    f(y)
    ```
    
    *
        ```
        void f(mytype const& x) {
            mytype x_copy = x;
            x.a = 42;
        }
        
        mytype y;
        f(y);
        ```
        
    *   ```
        void f(mytype& x) {
            x.a = 42;
        }
        
        mytype y;
        {
            mytype y_copy = y;
            f(y_copy);
        }
        ```
        
    Заметим, что иногда мы можем не делать копирование: в 1, если не присваивается ничего; во 2, если передается rvalue (можем заисопльзовать только один раз):
    ```
    f(mytype(1, 2, 3));
    ```
    С++ компиляторы устроены вторым вариантом, и копируют при lvalue, не копируют при rvalue.
    
2. При возвращении значения
    **Return-value optimization (RVO)**
    ```
    mytype g() {
        return mytype(1, 2, 3);
    }
    
    mytype r = g();  // резервирует место под результат, а g() на этом месте коструирует объект 
    ```
    Поэтому транслируется в примерно такое:
    ```
    void g(void* result) {
        // а тут как?
        // (*): конструтор - фукция, принимающая void* this и набор аргументов
        //      деструктор - аналогично, функция, принимающая mytype* this
        // можно подумать тут такой код:
        char tmp[sizeof(mytype)];
        mytype_ctor(tmp, 1, 2, 3);
        mytype_ctor(result, tmp);
        mytype_dtor(tmp);
        // но тут копирование bruh, поэтому так по причине (*):
        mytype_ctor(result, 1, 2, 3);
    }
    
    char x[sizeof(mytype)];  // align кривой, но для примера похуй
    g(x);
    ```
    Раньше на RVO не было требований, с С++17 по стандарту нужно реализовывать.
    Как следствие, рекурсивные коллы не плодят множество копирований, т.к поинтер на result у них равный у всех.
    А если возвращаем локальную переменную?
    ```
    std::string foo() {
        std::string tmp;
        for (;;) {
            tmp += ...;
        }
        return tmp;  // все крупные компиляторы умеют не копировать тут, думая что tmp лежит в result
    }
    ```
    **Named return-value optimization (NRVO)**
    ```
    void foo(std::string* result) {
        std::string_ctor(result);
        for (;;) {
            *result += ...;
        }
    }
    ```
    Такое можно невсегда сделать, например, если в момент создания переменной, которую мы вернем существуют пути исполнения, в результате которых мы вернем не эту переменную, то :( :
    ```
    std::string bar() {
        std::string a("abc");
        std::string b("cde");
        
        if (flag) {
            return a;
        } else {
            return b;
        }
    }
    ```
    
Иногда копирование сохдает проблемы:
```
    vector<string> v;
    string s;
    v.push_back(s);
```
Тут для произвольного типа Т вектор будет вынужден делать копирования при переаллокации вектора на другуя память, а для некоторых можно mem_cpy.
Для некоторых типов это свойство очень пиздово, если например vector<fstream>, то как копировать?
В С++03 так нельзя было писать, люди хранили указатели. А это сложно писать exception-safity и + это не кэш-френдли. Или через vector<shared_ptr<fstream>>.
unique_ptr тоже не копируемый, т.к. в деструкторе у него delete. Поэтмоу можем придумать следующую операцию:
```
unique_ptr(unique_ptr& other)  // move
    : ptr(other.ptr) {
    pther.ptr = nullptr;
}

void move(unique_ptr& oither) {
    delete ptr;
    ptr = other.ptr;
    other.ptr = nullptr;
}
```
Это позволило бы держать vector<fstream>, даже для тех классов, где нельзя предоставить копирование.
Но такая сигнатура мува не очень:
- rvalue не биндится в lvalue
-   ```
    vector<auto_ptr<mytype>> v;
    sort(v.begin(), v.end());
    ```
    Все указатели занулятся, т.к. там есть часть quick sort, который не копирует теперь, а мувает, тем самым разрушая все объекты вектора (pogue).
    
    
    
    
    
# Lecture 2. rvalue-ссылки
Непосредственно про ссылки
```
void push_back(T const&);
void push_back(T&&); // push_back_move;
```
```
struct mytype {
    mytype(mytype const&);
    mytype(mytype&&); // кэйс с autoptr сюда не подходит, т.к. rvalue не биндит от lvalue
    
    mytype& operator=(mytype const&);
    mytype& operator=(mytype&&);
};
```

В целом это всё.
lvalue -> rvalue:
```
vector<mytype> v;
mytype obj;
// v.push_back(static_cast<mytype&&>(obj));
v.push_back(std::move(obj));
```
Чтобы не писать каст, в стандартной библиотеки есть мув:
```
template <typename T>
T&& std::move(T& obj) { // тут про бинд & -> && не говорили , оригинальный мув другой
    return static_cast<T&&>(obj);
}
```
Мув это не приказ, а совет, будет ли там отбирание владения - зависит от реализации.

Нюансы:
1.  ```
    struct person {
        person(person const& name) 
            : name(name) {}  
        
        person(person&& name)
            : name(name) {}  // тут name это lvalue, т.к. он именнованный
            : name(move(name)) {}  // тут все ок, как ожидается
    
        // Не хочется писать кучу перегрузок, альтернатива:
        person(string name) 
            : name(move(name)) {}
        // так лучше писать, но тут больше операций, т.к. 1 копирование + 1 мув

    };
    ```
    ```
    return move(local_var); // ломает NRVO, да и в целом хуйня, которая не понятно зачем нужна
    ```
    Как проверить, выражение lvalue/rvalue?
    1.  Перегрузки
        ```
        void foo(mytype const&);  // 1
        void foo(mytype&&);  // 2
        
        mytype& lvalue();
        mytype&& rvalue();
        
        foo(lvalue());  // 1
        foo (rvalue());  // 2
        ```
    2.  Copy elision + RVO
        ```
        mytype test() {
            return lvalue();  // no RVO
            return rvalue();  // RVO
        }
        
        mytype x = lvalue();  // copy
        mytype x = rvalue();  // no copy
        ```
    
    ```
    mytype&& wtf();  // результат вызова это какая ссылка?
    foo(wtf());  // 2
    mytype test() {
        return wtf();  //  no RVO
    }
    mytype x = wtf();  // copy
    ```
    
Ситуация коненчо мемная получилась. wtf := xvalue - функция которая возвращает &&

lvalue := lvalue

rvalue := prvalue

xvalue:
* результат функции, возвращающий &&
* a.b где a это prvalue

После мува правая часть остается в "неопределенном, но валидном для испольщования состоянии".

Если бы мув был деструктивным, то есть удалял правую часть, то объект бы разрушался. Но тогда появляется сложнотсь в муве полей структур, т.к. какой-то один компонент тоьлко мувнулся, а развалилась вся структура.

const на ретурн типе запрешает мувать, не хорошо так делать.
        

    
    
    
# Lecture 3. Intrusive контейнеры

Суть в том, чтобы для задачи разделения списка юнитов на какие-то множества не использовать поиск этого юнита в листе, т.к. он большой и, несмотря на то что удаление за О(1), поиск там за О(n). Суть интрузивности -- хранить инфорпмацию о всех списках, в которых находится юнит прямо в юните, как бы прошивая еще одним двусвязным списком элементы множетсва, тогда для удаления какого-то юнита основного листа из его множества нам не придется искать этот элемент в том множетсве, т.к. для него мы знаем его соседей и просто сделаем ужаление, без поиска, за О(1).

Плюсы такого подхода:
+ Нет аллокаций/освобождений при всатвке/удалении элемента 
(актуально при больших объемах множеств)
+ Возможность использовать двусвязный список вместо хеш-таблицы 
(любопытный факт. Он дешевле в вопросе количества требуемых комманд, это по сути константа, а хеши считать все же дольше + локальность ссылок тут ахуеть просто, так что еще и претензии к спискам по поводу кэш-миссов снимаются, т.к. мы работаем всегда с памятью юнитов при переборе)
+ Лучшая локальность ссылок при итерации по элементам

Можно и обычный список приспособить лист к нелинейному поиску через backlink указатель элементов множетсва на элементы листа. Ровно это называют итераторами std::list. Вроде все супер, зачем интрузивность? 
Потому что память.

\+ интрузивности: Мы съэкономили на backlink и value, т.к. указатели элементов множетсва есть и в интрузивной версии.
\- интрузивности: Если элемент не выделен в множество для него все равно хранится интрузивные prev/next поинтеры.

Когда элементов мало это бррр.
А поскольку у нас в хипе меньше объектов это выигрыш в виду накладок аллокаторов.

Всё выше можно обобщить на деревья поиска, списки, хеш-ттаблицы, использующие листы для разрешения коллизий. (LRU-кеш так делает вроде)

**Теперь о том как это все хранить**
- С стайл: структурка с прев/некст поинтерми, в юните статично лежат ноды с поинтерами
Тогда чтобы получить укзатель на юнит имея указать на ноду можно сделать containerof := ptr - offsetof(node, member)
(в ядре Линукса реально такое написано) И нет поводов этому не работать, но в спп иногда ВыЛеЗаЕт ВоРнИнГ с наличием виртуальных функций, например, оффсетов не очень хорошо считается
- Спп стайл: каст от дерайвед к базе сдвигает указатель. Значит можем наследоваться! Только надо шаблонным базы сделать, чтобы индентифицировать их можно было. (ну или делать промежуточные базы бррр)

Но важно, что эти два подхода оба корректны, и там где у одного нет ошибок при касте, не будет и второго, и, наоборот, где они есть у первого, там и будут у второго.

Собственно в этом и заключается интрузивность:
1. не создает сам элементы, а работает с тем что ему передали (в инсерт, в ремув)
2. требует от элементов содержать какие-то дополнительные данные, для прошивки их в списки

Прикольный юз-кейс интрузивных сд:
```
struct person {
  string name;
  string id;
  string company_name;
  size_t age;
};
```
Можем добавить возможность поиска по имени, паспорту, компании, путем провязки соответсвующих полей в интрузивные деревья. (В бусте такой контейнер называется multi_index)

    
    
    
    
# Lecture 4. shared_ptr 

Такой же смарт-поинтер, как и unique_ptr, с единственным отличием -- возможностью копироваться, а удален объект будет, когда удалиться последний из shared_ptr'ов, ссылающихся на него. То есть это указатель, который хранит счетчик ссылок и сам объект. Ремарка сразу, счетчик лежит в отдельном сontrol block, а в поинтрее лежит указатель на объект и контрол блок. 

shared_ptr только отвечает за удаление, а не за доступ к объекту, можно и обычные указатели делать на этот объект. (это очевидно, да, но сорокин упомянул лишний раз)

Шаред поинтер рассчитывает на удаление по delete, так что если это кастомно создается, то надо сообщать ему делитер, которым он будет удалять -- функция, которая будет вызван, когда счетчик ссылок == 0. Делитер лежит там же в контрол блоке. На самом деле тут еще птр ледит на оригинальный объект, потом в алясинг конструкторе это сыграет, чтобы уметь удалять спокойно. 

**Aliasing constructor**
Проблема машины и колеса, если машина умерла, а кто-то ссылается на его колесо, то он спокойно продолжит использовать колесо которое никакой машине уже не принадлежит, что странно. shared_ptr иногда хороший способ хайдить ошибки путем простого продления времения жизни объекта. 

То есть, мы хотим интерфейс, позволяющий хранить машину и колеса как единое целое. Тогда решение называется алясинг конструктор. Это конструктор от шаред поинтера, с которым мы разделин контрол блок:
```
struct wheel {};

struct vehicle {
  std::array<wheel, 4> wheels;  
};

std::share_ptr<vehicle> v(new vehicle());
std::shared_ptr<wheel> w(v, &v->wheels[2]);  // ссылается на 3-е колесо, но делит контрол блок с v
```
Заметим, что тут wheel не может иметь кастомный делитр, т.к. тогда мы хотим разное поведение для объемлющего объекта и его состовляющего, что в целом странно.

Тема с машиной и колесом -- типичный юз кейс алясинг конструктора


Особенность реализации шаред поинтера - две аллокации, по new и по аллокации контрол блока

Этого можно избежать, для этого есть функция make_shared, в который передаются аргументы конструктору, она аллоцирует блок памяти, где одновременно будет контрол блок и наш объект (за одну алокацию), вызовет там конструкторы и вернет шаред поинтер на то, что она создала (я писал вроде через создание инплейс контрол блока и использование его птр'а):
```
struct mytype {
    mytype(int, int, int);
};

std::shared_ptr<mytype> p = std::make_shared<mytype>(1, 2, 3);
```

Стоит использовать make_shared, потому что он крутой. Если передавать в аргумент функции шаред поинтеры (а они вычисляются в произвольном порядке), и второй из них может кинуть excrption, тогда память первого ликнет. А make_shared самостоятельно создаст объект и обернет его, для нас это будет как оусловно одна операция, который не ликнет в таком случае. 


**weak_ptr**
Возможность делить контрол блок, не мешая ему удаляться. Он позволяет создаваться от шаред поинтера, и имеет функцию lock(), которая возвращает shared_ptr от этого объекта, если он еще живой или нулловый шаред поинтер, иначе.

Тогда надо похранить два счетчика ссылок в констрол блоке (обычно пишут с инвариантом, что strong_link != 0 <=> weak_link > 0, тогда будет меньше ебли с проверками). А контрол блок теперь удаляется при weak_link == 0, а объект при strong_link == 0

Юз кейс вик поинтеров -- кэши. Виджет живет в кеше, пока на него кто-то ссылается, то есть сам кеш не мешает ему умирать: 
```
shared_ptr<widget> get_widget(size_t id) {
    static map<int, weak_ptr<widget>> cache;
    auto sp = cache[id].lock();
    if (!sp) {
        cache[id] = sp = load_widget(id);
        // тут sp - shared_ptr, поэтому корректно получается:
        // weak_ptr = (shared_ptr = shared_ptr)
    }
    return sp;
}
```
Но этот код не очень корректный код, там мапа будет анбаунд расти :) Но оно и понятно, человек писал этот код чтобы просто выебнуться, кажется.


Проблема анбаунд роста еще и в том, что помимо объектов, которые не удаляются не удаляются и контрол блоки у объектов, которые удаляются, но попрежнему лежат в мапе

Дальше рассказ про фикс этой проблемы (это начало лекции #5 для y2020 ~ первые 30 минут оттуда)
Самая простая идея -- кастомный делитер, чтобы удалять из мапы при удалении и чистил память за собой. Тогда weak_link-- при удалении из мапы, тогда и удалится контрол блок. Таким образом, в мапе не будет протухших виков, посколько он удалится оттуда при разрушении.


Если есть желание возвращать из функции шаред поинтер на объект, то с обычными функциями все ок, но есть проблемы с this:
```
std::shared_ptr<mytype> foo(std::share_ptr<mytype> const& p) {
    return p;  // ok
}

struct mytype {
    std::share_ptr<mytype> bar() {
    return shared_ptr<mytype>(this);  // тут каждый раз будет создаваться новый контрол блок, что как-то не то что мы хотим, поэтому вариант ниже - решение
};


struct mytype : std::enable_shared_from_this<mytype> {
    std::share_ptr<mytype> bar() {
    return std::shared_from_this();  // внутри хранит вик птр на себы и в нужный момент его лочит
};
```

Так же, как есть касты для обычных указателей, так же есть и для шаред птр весь набор. Они кастуют указатель с сохранением контрол блока.


    
    
    
# Lecture 5. lambda

Тут пример про сортировку и то, как передать туда компаратор: 1 - как функцию (T const& a, T const& b), 2 - как оператор() у какого то класса. По тестам получается, что 1-ый вариант медленнее. Почему? тут связано с тем, сколько время проводится в сорте и сколько в колбэке. Проблема в том, что компилятор не может инлайнить функцию в первом варианте:

Как вообще организовать sort?
1.  шаблонно по компаратору
    ```
    template <typename Sort>
    void sort(Comp cmp) {
        ...
        cmp(a, b);
        ...
    }
    
    struct less {
        bool operator()(int a, int b) const {
            return a < b;
        }
    };
    
    sort(less());
    ```
2. принять указатель на функцию
    ```
    void sort(bool (*cmp)(int, int)) {
        ...
        cmp(a, b);
        ...
    }
    
    bool less(int a, int b) {
        return a < b;
    }
    
    sort(&less);
    ```
    
Вроде одно и то же, но разница в том, что если будут вызовы сорт с разными компараторами, то в 1м случае нагенерится куча кода, где можно инлайнить тело компаратора, а во 2м особо ничего не сделать, т.к. функция одна, а вызов функции тяжелый из-за сохранения регистров и прочей возни перед jump. + компилятор может лучше оптимизировать при инлайне, т.к. ему больше информации известно из окружения.

Это сравнение называется **разница между статическим (1) и динамическим (2) полиморфизмом** (с разными объектами работаем одинаково)

Но есть и минусы у статического:
* компайл-тайм штука => менее гибкий, ограничевается возможность действий над такими компараторами
* генерирует больше кода => меньше шансов попасть в кеш :(

Если скомпилировать с -O2 -flto (linking time optimization -- оптимизация между всеми .cpp не на этапе трансляции, а на этапе линковки [тогда например, можно инлайнить тела функции из одной еденица трансляции в дргую]), то разница пропадет, но это странно, у нас был один .спп .

Если добавить сравнение еще и про greater, то разница опять появляется. Это потому что раньше уомпилятор понял, что в динамическом варинте всегда пихают одну и ту же функцию, и просто инлайнул ее. Поэтому нельщя говорить, что разница в полимозфизмах это хуйня, и скидывать все на компилятор, пусть он разбирается.

То же самое с -O3 -- разницы снова нет. Тут вклад от -fipa_cp_clone, которая в -O3 есть. Суть в том, чтобы делать копии для каких-то констант, что может быть полезно. Тут полезно, и он откопировал динамический сорт. (обычно этот ключ выключен, т.к. просто бесполезен)

Еще один сорт оптимизаций: девиртуализация. Суть: заметить, что часто на месте динамической функции используется какая-то конкретная, подменить ее вызов ифом на сравнение с той, которую мы заметили. Тогда магия скедуллера все сделает + заинлайнили less.
```
void sort(bool (*cmp)(int, int)) {
    for (;;) {
        ...
        if (cmpr == less) {
            less(a, b);
        } else {
            cmp(a, b);
        }
        ...
    }
}
```
На самом деле этот иф -- инвариант всего фора, и там не просто инлайн less, там ?инлайн? всего фора:
```
void sort(bool (*cmp)(int, int)) {
    if (cmpr == less) {
        for (;;) {
            ...
            less(a, b);
            ...
        }
    } else {
        for (;;) {
            ...
            cmp(a, b);
            ...
        }
    }
}
```
MAGIC

Это все круто конечно в большинстве функции, но если важно, насколько эффективный сорт, то тут есть недостаток в виде огромного бинаря, зависящего от кучи факторов.

Этот трик хорошо работает вместе с **PGO (profile-guided optimization)** -- оптимизация, когда дважды компилируется программа: 1ый с подсчетом статистики и запуске на своих тестах, 2ой с применением оптимизации статистикой. -fprofile-generate -fprofile-use.

Про статический и динамический полиморфизм всё

**Анонимные функции**
Хотим отсортировать массив modulo 5. До С++11 - напишем функциональный объект с оператором() (1).
\+ решение, если используется повторно
\- иначе долго писать и непоянтно зачем это надо
\- ПрИдУмАтЬ иМя

С С++11:
```
[](int a, int b) {return a % 5 < b % 5;}  // (2) 
// это лямбда, и (2) эквивалентна (1)
```

Лямбда -- класс с именем, которое нам неизвестно, есть оператор() с тем что передано в () и {}

**Синтаксис лямбд**
1. захватывается с контекстом
    если осртировать по модулю N, в (1) надо хранить его в классе, в (2):
    [n](int a, int b) {return a % n < b % n;}  // говорят "захватывает n"
    Можно такое: 
    - []  // ничего
    - [a, b, c]  // по значению
    - [a, b, &c, &d]  // 3 и 4 по ссылке
    - [&, c, d]  // все по ссылке, c и d по значению
    - [=]
    - [&]
    - [this]  // [=] [&] тоже захватывают this, но можно и явно

    Важно, в [] только локальные переменные и аргументы, глобальные переменные там быть не могут (очевидно)
    
2. Может захотеться иметь шаблонный оператор()
    Тут про разницу шаблонности класса и шаблонности метода, и в разных кейсах хочется по разному. Для лямбд есть два спасоба:
    1. ```template<typeaname>(T a, T b)```
    2. ```(auto a, auto b)``` <=> ```template<typename A, typename B>(A a, B b)```
3. ретурн тип можно написать через ```->```

Лямбда *без захвата* может приводиться к указателю на функцию. Тогда тот пример с modulo N для динамического сорта не реализовать, надо обарачивать в функцию принимающую еще и N и на нем вызывать cmp.

Лямбда не имеет дефолного конструктора, оператора=, но могут копироваться и муваться (до С++20). В С++20 лямбдам без захвата рарешили дефолт конструктор и опратор=.

А зачем дефолт конструтор? В целом не зачем, раз не было. Но поскольку даже пустой класс имеет размер 1 байт из-за *паддинга* (std::bind [кто это?] хранит в себе кучу пустых объектов => имеет большой вес) -- по свойству различия адресов любых объектов. Можно наследованием обойти, но \-: если компаратор final, то сосем. Альтернатива -- [[no_unique_address]] (C++20) атрибут, говорящий разместить где-то, похую на адрес (вероятно, адрес этого объекта будет просто this)


    
    
    
# Lecture 6. std::function

Понятно, что поскольку лямбда генерирует новый класс, то в сорте будет статический полиморфизм, и всегда будет быстро :)

Но что, если хочется разные виды динамического полиморфизма?
```
if (flag) {
    func = []() {...}
} else {
    func = []() {...}  // или std::less
}
```

Тоже понятно, что так не написать, т.к. это совершенно разные типы. Как писать? 
? Указатель? 
\- Только если лямбда капчерит ничего 

```
(flag == true ? []() {...} : []() {...});  // в тернарнике это тоже разные типы если что
```


Решение:
**std::function<bool (int, int)> func;**

Как такое написать? (на самом деле там целая практика была, но ладно я нотесы поделаю хули мне)

Про мемную сигнатуру - это сигнатура функции, эмулируется так:

```
template <typename T>
struct function;

template <typename R, typename ...Args>
struct function<R (Args...)>;
```
Дальше описан function<int (int)> чтобы не ебаться с шаблонами.
```
struct function {
    template <typename F>
    function(F f) 
        : p(new F(move(f))) {}
    
    // деструктор написать не можем, поскольку для delete надо знать тип, а он void* :O
    // можно сохранить делитер в конструкторе, т.к. мы его там знаем
    
    void* p;  // тут непонятно, что хранить, но пусть будет void* пока
};
```
Есть два принципиальных подхода: с наследованием и без (о, как неожиданно ебать).
Hint:

```
template <typename F>
void destroy(void* p) {
    delete static_cast<F*>(p);
}
template <typename F>
void destroy(void* p, int arg) {
    return (*static_cast<F*>(p))(arg);
}
```
Тогда:
```
struct function {
    template <typename F>
    function(F f) 
        : p(new F(move(f))),
        deleter(&destroy<F>) 
        invoker(&invoke<F>) {}
    
    ~function() {
        deleter();
    }
    
    // invoke аналогично dtor
    
    void* p;
    void (*deleter)(void*);
    int (*invoker)(void*, int);
};
```
(на практике вроде наследовался)

Статически полиморфные лямбды и динамически полиморфные std::function позволяют управлять тем, какой нужен полиморфизм, где.


**boost::any**
Хранит вообще всё, что копируется, привет джс.

*Напоминалка про виртуальный деструктор*
Можно сделать обертку над Т и базу, нешаблонную базу, чтобы эту обертку сохранить в эни.
```
struct concept_ {
    virtual ~concept_() {}  
};

template <typename T>
struct model : concept_ {
    model(T value)
        : value(move(vlaue)) {}
    
    T value;
};

struct any {
  template <typename T>
  any(T val) 
    : p(new model<T>(move(val)) {}
  
  ~any() {
      delete p;  // можно и unique_ptr тут вообще
  }
  
  concept_* p;
};
```

Как any_cast сделать? Виртуальная функция не может быть шаблонной, т.к. нам их окнечное число можно позволить. А тут в концепт надо засунуть. Вроде dynamic_cast подойдет. Или через typeid что-то.

Можно function и any реализовывать обоими способами.

Тогда вопрос, а как any_cast делать в случает написания как для function, когда динамик каста нет и тайпадйи тоже, т.к. они работают с виртуальными функциями только. Можно проверить ```deleter == &destroy<mytype>```, так можем узнать, лежит ли в нас mytype. (красиво)


Заметим, что оба способа не хранят явно тип объекта, это называется **Type Erasure**

Об этом можно думать, как о забывании информации о том какой у нас функциональный объект, поскольку нам важны только его функциональные части -- что принимает, что возвращает.


Экскурсия в зоопрарк, привет КПК: **boost::any_iterator<int>**. Если хочется полимормно пользоваться интераторами листа и вектора, например, похожие же структуры.. И пусть даже забъем, что итераторы бывают пяти разных категорий (напоминалка: input, output, forward, bidirectional, random-access) Тогда мы срезаем инфу, что это итератор на вектор, но оставляем, что он на инт. (в бусте есть any_range :| ) И вообще люди пробуют библитеку any_всего написать.

Тайп эрейзнутые классы напоминают наследование, как альтернатива ему.

Мнения по тайп эрешью?
    
\+: Наследование интрузивное, а мы нет
То есть интератор должен знать, в каких полиморфных отношениях он используется -- это плохо, поскольку что-то будучи полиморфным, не всегда самая очевидная вещь. 

\+: Value-семантика.
    Чтобы пользоваться классом полиморфно надо передавать на него указатель или ссылку. Тогда для вектора таких any надо хранить указатели, а значит виртуальные деструткоры :/ или смарт-поинтры
    **value-семантика** -- про объекты с которыми просто работать в плане копирования и т.д. (std::vector, например, а поинтеры это нет)
    Так вот, виртуальные функции вынуждают пользоваться указателями, теряя value-семантику. А тайп эрезнутые ее имеют
    
\+-: привязанность к динамическому стораджу
    Можно избежать путем small object, но когда у нас дохуя альтернатив, sorry, от динамических аллокаций особо никуда не деться.
    
\+: позволяет не пользоваться полиморфизмом, без доплаты за это

Почему тогда any нет в std? Он бесполезный :) Типо any_iterator убивает множество оптимизаций, поэтому большого смысла в них нет. 

Throwback to function:
как написать тайпдеф на указатель на функцию?
```
void (*deleter)(void* p);
typedef void (*deleter_t)(void* p);
```

Шаблонный тайпдеф := using (а typedef не рассширен до шаблонов)
```
template <typename T>
using deleter_t = (*)(T* p);
```

    
    
    
   
# Lecture 7. Сигналы


signal = listener = observer. Это рассказ НЕ ПРО UNIX сигналы.

Зачем это нужно? Это подписка на событие -- вызов callback после произошедствия какого-то действия. Поскольку одного callback может быть недостаточно, то сигналом называют _контейнер function'ов_.

По этому тоже была практика, которую лучше почитать, т.к. там описывались поинтереснее решения всяких проблем, тут нотесы с кодом тоже будут, но, возможно, не так подробно.

Наивно это выглядит так:
```
struct signal {
    using slot_t = function<void()>;
    
    void connect(slot_t slot) {
        slots.push_back(move(slot));
    }
    
    void operator()() const {  // это immit
        for (slot_t const& slot : slots) {
            slot();
        }
    }
    
private:
    vector<slot_t> slots;  // callback называют слотом, соу это они  
};
```

Хочется конечно и disconnect иметь. connect в свою очережь обычно возвращает какой-то connection, удобно его итебатором сделать, да и для дисконнекта мапа приятнее будет. So:
```
strcut connection {

    // ctor 
    
    void disconnect() {
        size_t c = sig->slots.erase(id);
        assert(c == 1);
    }
    
    signal* sig;
    id_t id;
};

struct signal {
    using id_t = uint64_t;
    using slot_t = function<void()>;
    
    connection connect(slot_t slot) {
        id_t id = next_id++;
        slots.insert({id, move(slot)});
        return connection(this, id);
    }
    
    void operator()() const {
        for (auto it = slots.begin(); it != slots.end(); ++it) {
            it->second();
        }
    }
    
private:
    unordered_map<id_t, slot_t> slots;
    id_t next_id = 0;
};
```

Это похоже на правду, но он часто не приминим, т.к. будет ломаться при некоторой последовательности вызовов наших функций. + если какой-то колбэк не ноуэксепт, то вроде получаем странное поведение, однако многи ебилиотеки кладут хуй на это, в том числе и буст, так что последуем их примеру и не будем писать трай-кэтч с логированием.

Проблема тут в следующем, рассмотрим такой класс:
```
struct mytype {
    mytype()
        : c(global_timer.connect(
            [this]{on_timer_elapsed()}
            )) {}
    
    void on_timer_elapsed() {
        c.desconnect();
    }
    
    connection c;
};
```
Логика такая: подписались, произошло событие, мы отписались. Не то что бы редкий случай.  Тогда проблема в оператор(), поскольку при дисконнекте инвалидируется интератор, рассмотрим коллстэк:
```
operator()
|---on_timer_elapsed()
    |---disconnect()  // тут и сломается при ++it
```

Решить можно созданием очереди на удаление: если мы находимся в опереторе() и делается дисконнект, то просто забьем пустым фанкшеном нужный слот, и потом прочистим мапу. Если просто вызван дисконнект, то честно можено удалить слот, поэтоу заведем еще и флаг, в иммите мы дисконнектимся или нет (иначе мапа будет анбунд расти, если коннекты и дисконнекты случаются, а иммит не вызывается) + так как теперь мы удаляем слоты в константном иммите, сделаем мапу мутабельной:

```
strcut connection {

    // ctor 
    
    void disconnect() {
        if (sig->inside_imit) {
            auto it = sig->slots.find(id);
            assert(it != sig->clots.end());
            it->second = slot_t();  // отмечаем, что слот удален
        } else {
            size_t c = sig->slots.erase(id);
            assert(c == 1);
        }
            
    }
    
    signal* sig;
    id_t id;
};

struct signal {
    using id_t = uint64_t;
    using slot_t = function<void()>;
    
    connection connect(slot_t slot) {
        id_t id = next_id++;
        slots.insert({id, move(slot)});
        return connection(this, id);
    }
    
    void operator()() const {
        inside_imit = true;
        for (auto it = slots.begin(); it != slots.end(); ++it) {
            if (it->second) {
                it->second();
            }
        }
        inside_imit = false;
        
        for (auto it = slots.begin(); it != slots.end(); ) {
            if (it->second) {
                ++it;
            } else {
                it = slots.erase(it);
            }
        }
    }
    
private:
    mutable unordered_map<id_t, slot_t> slots;
    id_t next_id = 0;
    mutable bool inside_imit = false;
};
```
Какие теперь тут проблемы?
- смущает пара inside_imit = true/false, можно обернуть в РАИИ. Т.к. она не эксепшн-сэйв, фикс:

```
    void operator()() const {
        inside_imit = true;
        try {
            for (auto it = slots.begin(); it != slots.end(); ++it) {
                if (it->second) {
                    it->second();
                }
            }
        } catch(...) {
            inside_imit = false;
            throw;
        }
        
        inside_imit = false;
  
        for (auto it = slots.begin(); it != slots.end(); ) {
            if (it->second) {
                ++it;
            } else {
                it = slots.erase(it);
            }
        }
    }
```

- еще проблема: наш инвариант - будучи внутри иммита, мы можем иметь пустые слоты, по выходу из иммита их в мапе быть не должно. Тогда прочистку надо делать и внутри кэтча:
```
    void leave_immit() {
        inside_immit = false;
        for (auto it = slots.begin(); it != slots.end(); ) {
            if (it->second) {
                ++it;
            } else {
                it = slots.erase(it);
            }
        }
    }
    void operator()() const {
        inside_imit = true;
        try {
            for (auto it = slots.begin(); it != slots.end(); ++it) {
                if (it->second) {
                    it->second();
                }
            }
        } catch(...) {
            leave_immit();
            throw;
        }
        
        leave_immit();
    }
```
- Все равно хуйня: до сих пор выставляем пару тру-фолс у inside_immit, а представьте такой коллстэк:
```
operator()
|---handler()
    |---operator() // по выходу inside_immit == false;
    |---disconnect() // получили инвалидный итератор
```

Варианты?
1. ЗаПрЕтИтЬ (потому что нахуй такое поведение вообще поддерживать)
2. пофиксим просто? (ведь может быть такое) подсчитывая глубину inside_immit (вообще такие реализации с флагами в тру/фолс много когда сосут при рекурсии, лучше так не делать)

```
strcut connection {

    // ctor 
    
    void disconnect() {
        if (sig->inside_imit != 0) {
            auto it = sig->slots.find(id);
            assert(it != sig->clots.end());
            it->second = slot_t();  // отмечаем, что слот удален
        } else {
            size_t c = sig->slots.erase(id);
            assert(c == 1);
        }
            
    }
    
    signal* sig;
    id_t id;
};

struct signal {
    using id_t = uint64_t;
    using slot_t = function<void()>;
    
    connection connect(slot_t slot) {
        id_t id = next_id++;
        slots.insert({id, move(slot)});
        return connection(this, id);
    }
    
    void leave_immit() {
        --inside_immit;
        for (auto it = slots.begin(); it != slots.end(); ) {
            if (it->second) {
                ++it;
            } else {
                it = slots.erase(it);
            }
        }
    }
    void operator()() const {
        ++inside_immit;
        try {
            for (auto it = slots.begin(); it != slots.end(); ++it) {
                if (it->second) {
                    it->second();
                }
            }
        } catch(...) {
            leave_immit();
            throw;
        }
        
        leave_immit();
    }
    
private:
    mutable unordered_map<id_t, slot_t> slots;
    id_t next_id = 0;
    mutable size_t inside_imit = 0;
};
```

Попрежнему есть проблемы, но в том коде, который еще не написан :|  Деструктор сигнала может быть вызван внутри иммита. Разъёб просто! И такое реально встречается: создается таймер, который при тике удаляется -- ровно этот случай. А у нас будет проблема в иммите тогда, поскольку мапа, по которой итерируемся, протухнет и всё. Чо делать? Флаг не поставить, он же при удалении сигнала и сам удалится. Идея -- сделать это без динамических аллокаций, типо можно было просто в шаред_птр обернуть мапу и жить. Сохраним указатель на локальную переменную, уничтожены мы или нет, тогда эта переменная не будет разрушена при разрушении класса: 

```
strcut connection {

    // ctor 
    
    void disconnect() {
        if (sig->inside_imit != 0) {
            auto it = sig->slots.find(id);
            assert(it != sig->clots.end());
            it->second = slot_t();  // отмечаем, что слот удален
        } else {
            size_t c = sig->slots.erase(id);
            assert(c == 1);
        }
            
    }
    
    signal* sig;
    id_t id;
};

struct signal {
    using id_t = uint64_t;
    using slot_t = function<void()>;
    
    connection connect(slot_t slot) {
        id_t id = next_id++;
        slots.insert({id, move(slot)});
        return connection(this, id);
    }
    
    ~signal() {
        if (is_destroyed) {
            *is_destroyed = true;
        }
    }
    
    void leave_immit() {
        is_destroyed = old_destroyed; // понятно, что это нескомпилируется, но похуй, это же пример :)
        // по хорошему надо бы написать РАИИ класс где можно похранить old_destroyed
        --inside_immit;
        for (auto it = slots.begin(); it != slots.end(); ) {
            if (it->second) {
                ++it;
            } else {
                it = slots.erase(it);
            }
        }
    }
    void operator()() const {
        bool* old_destroyed = is_destroyed;  // чтобы не сломать рекурсию
        bool flag = false;
        is_destroyed = &flag;
        ++inside_immit;
        try {
            for (auto it = slots.begin(); it != slots.end(); ++it) {
                if (it->second) {
                    it->second();
                    if (flag) {
                        old_destroyed = true; // тут передаем выше флаг, что мы разрушены
                        return;
                    }
                }
            }
        } catch(...) {
            leave_immit();
            throw;
        }
        
        leave_immit();
    }
    
private:
    mutable unordered_map<id_t, slot_t> slots;
    id_t next_id = 0;
    mutable size_t inside_imit = 0;
    mutable bool* is_destroyed;
};
```
Заметим, что теперь вроде все работает, но это можно и подупростить:
- не нужен inside_immit -- мы можем определять это по флагу is_destroyed
- не нужна мапа с айдишниками -- можно использовать лист для слотов, тогда айдишником будет итератор листа


В итоге получаем, что простая на первый взгляд идея выглядит как полный пиздец. А вообще зачем это все?
1. Не пытайтесь писать подобные классы самостоятельно, пользуйтесь библиотеками, чтобы не породить множество проблем, которые, как видим, не сложно породить. Однако, обязательно изучите, какие гарантии она предоставляет, потому что мы здесь описали весьма полно. Часто в реализациях не выполняется свойство, что после дисконнекста слот не будет вызван. Что запрещает отписываться в деструкторе. треш..
2. Если конечно не хочется тащить библиотеку только из-за сигнала, можно ебануть самописанный сигнал, но ассертить все кэйсы, которые могут возникнуть, но бы не хотели их видеть. Благо сейчас мы знаем эти кейсы.
3. Те проблемы при последовательности вызовов одних функций внутри других имеет название -- **reentrancing**. В 80-90ых это много обсуждалось, сейчас всем как-то похуй. Это потому что раньше часто пользовались глобальными переменными, а сейчас все такие люди "передохли" (с). Поэтому реэнтрабельность кода сейчас второстепенная проблема, которая часто и не возникает, однако, как видим, она бывает актуальна и без глобальных переменных.


Мораль всей истории: защищая свой код от внешнего воздействия, подумайте о том, насколько защищен ваш код внутри себя. Если мы вызываем кого-то наружу, что он может вызывать обратно у нас? И обратно, если пишешь обработчик.

Получилось какое-то филосовское завершение. Но даже локально при наследование такие проблемы могут возникать -- базовый класс вызывает производный, какие тогда функции может обратно вызывать производный, чтобы ничего не ебнулось в совокупности.

    
    
    
    
# Lecture 8. Обработка ошибок

Кейс из жизни отца:
```
FILE* f = fopen(...)
assert(f);
```

Тут некооректен ассерт, поскольку это отключаемый механизм, а ошибку неоткрытого файла хочется в любой сборке ловить. Ассерты ок для проверки инфариантов класса в дебаге. Может появиться вопрос, а зачем их отключать? 

1. performance.
Понятно, что проверки долгие и в релизе их проверять ахуеть можно, т.к. там примерно половина времени работы будет в проверке ассертов по-хорошему

2. Чтобы не пытаться оптимизировать проверки. Иначе можно ошибиться в проверке не отловить какой-то случай. Да и в целом оптимизировать проверку звучит как-то странно в контексте реализации класса.


Понятно, что слово "ошибки" достаточно многообъемлящее. Поэтому обозначим то, о чем не будет рассказано:
1. Hardware error (потому что особо нет механизмов отлавливать эти ошибки)
2. Compilation error (они лучше чем runtime error, потому что их ловить проще)
3. Случаи, когда программа внутренне не противоречит сама себе, но выдает ответ, отличающийся от того, что ожидает пользователь


Что у нас отсается:
1. Internal consistency error
2. Rare/uncommon cases (файл не открылся, по сути это не ошибка, а вполне возможный случай)

Способы решения их:
1. Ignore
2. Abort
3. Propogate to caller (exception/error code)
4. Log & continue


Стандартный мезанизм ассертов делать 1 или 2 в зависимости от сборки.
Вообще понтие ошибки отличается для разных людей. Если ты пишешь код и он где-то аварийно завершился с ошибкой, то для тебя это перестает быть ошибкой, как только ты пофиксил это. А если ты юзер библиотеки и она каким-то образом крашится, то для тебя это вполне ошибка. Так же и подходы разные к решению таких проблем, где-то может быть выгодно забить, а где-то быстро убить программу, чтобы она не испротила какие-то глобальные ланные и после перезапустить ее.

Обсудим маэтчинги ошибок и решений на предмет разумности:

1 + 1 : странно, но можно, когда долго проверять (ассерт в релизе)

1 + 2 : могут быть претензии со стороны кода, который пользуется твоей библиотекой, типо хули ты своим маленьким кодом сломал мне всю программу. Но с другой тут вопрос альтернатив, а что делать то в таком случае? Если, например, вызвали сорт, и не получилось отсортировать, то нам просто вернуть неотсортированный массив? weird.

1 + 3 : вообще юзер не ожидает ошибки от кода которые он использует. И вообще, что ему делать, если ему сообщили, что не смогли сделать то, что он потребовал? Поэтому обычно так не делают. Но если это делать бросанием эксепшена, то вроде все ок.
Ассерт у которого альтернативы 1 или 3 звучит странно, поскольку мы плодим сами множество мест, где потенциаьлно могут возникнуть эксепшены, именно из-за ассерта.

1 + 4:
Ассерт с альтернативами 1 или 4? По сути программа в дебаге и релизе работает одинаково и это не мотивирует исправлять ошибки. 

Совет от отца: писать ассерты везде где ты рассчитываешь на какое-то конкретное поведение программы.

2 + 1 : можем проигнорить, если можем задать какое-то стандартное поведение для программы в таком случае. Либо второй вариант: признать такой подхож ебланством и не делать так никогда.

2 + 2 : есть ли какие-то +? 
\+ Если делать ошибку аллокации памяти не эксепшеном а абортом, то сразу получаем множество мест, где становится проще писать эксепшен-сейфти код.
\- такие проверки это сложновато писать, т.к. занять всю память машины звучит не прям чтобы просто => тяжелее отлаживать.
\+ надо понимать, из-за чего именно возникла ошибка аллокации. Если это из-за ликов, то возможно лучше убить программу и перезапустить, чтобы она не висела в полумертвом состоянии.
\+ (слабый аргумент, не буду про него писать) про overcommit в линуксе.

Помимо ошибок аллокации памяти тут же может быть моменты с отсутствием файлов которые надо подгрузить в игру в какой-то момент из-за воздействия юзера. Тогда абортить звучит разумно, потому что а что делать? Важно, что в эксепшене заинтересован только тот код, который ожидает от тебя успешного выполнения. Если он от тебя ничего не ожидает, то странно полагать, что он будет рассматривать все кейсы твоего поведния (как например с сигналом было, он же просто колбэки вызывал)

2 + 3 : никто не будет спорить, что в 99% случаев это и применяется

Может возникнуть вопрос, а можно как-то потестить программу, если мы знаем что в ней может быть бага, но чтобы она ничего не сломала? Есть в ОС механизм запуска новых процессов. Это как раз и решение (хотя звучит как само собой разумеется)

    
    
    
    
# Lecture 9. Кодировки

На самом деле, тут только про UNICODE будет

"Если вы что-то и вынесете с этой лекции, то как минимум то, что от размера char ничего не зависит" (с)

Мотивация:
1. "Мой код использует 16-битные чары, значит все точно хорошо"
2. Раньше особенно -- кривая работа с текстом (ex: в браузере один символ стирается одним бэкспейсом, другой - двумя pogue)

Что такое Юникод?
Система сопоставления **code point (cp)** какой-то реальной букве. Диапазон код поинтов: [0, 0x10FFFF) ~ [0, 17*2^16) Какое-то кривое число, да? Да и 16-битный чаров явно уже не хватает.

А как хранить?
1. Самый неэфективный способ -- USC-4 он же UTF-32 -- 32-битное число, явно покрывает весь диапазон. Это число называется **code unit (cu)**
2. 16-битноый код юнит -- UTF-16 (USC2 актуально до 1996 -- code point == code unit, но понятно, что сейчас туда весь диапазон не влезет)
3. 8-битный код юнит -- UTF-8

Помним, что существуют эндианы, тогда каждая из кодировок разбивается на еще две: LE, BE. Но это актуально только в контексте байта, не чара.

Примерный алгоритм: срока -> код поинты -> код юниты

**Как представляются UTF-16** ?
Диапазон [D800...DFFF) объявляется не валидным.
Если cp < 0x10000 то cp = cu
Иначе, cp >= 0x10000:
cp -= 0x100000
cp in [0...0xFFFFF]  // 20 bits = 10 + 10 bits
cu = cu1 + cu2, где cu1 in [0xDC00...0xDFFF], cu2 in [0xD800, 0xDBFF] Это называется **суррогатная пара**. cu1 и cu2 как рах занимают тот невализный диапазон. 

Очевидно, хочется, чтобы такие суррогатные пары удалялись как пары, а не по одному суррогату, инвалидируя тем самым строку.

**Как представляются UTF-8** ?
Там прикол. По сути хочется кодировать такой огромный диапазон 8-битными чарами, для этого придумали следующий трик: если число принадлежит какому-то рэнжу, то его длина равняется фикс кол-ву чаров (0-4), причем старшие биты каждого лидирующего чара подобраны так, что они позволяют точно определить сколько чаров занимает код юнит. А среди всевозможных видов представить этот код поинт, нужно выбирать наименьший по количеству юнитов (называется отвержением overlong sequinces) 
Вообще это материал с вики, вот [сурс](https://ru.wikipedia.org/wiki/UTF-8)

| Количество код юнитов |	Значащих бит |	Шаблон | 
| - | - | - |
| 1 |	7 |	0xxxxxxx |
| 2 |	11 | 110xxxxx 10xxxxxx |
| 3 |	16 | 1110xxxx 10xxxxxx 10xxxxxx |
| 4 |	21	| 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx |

Крутая штука UTF-8 BE, что a_cp < b_cp <=> a_utf-8 < b_utf-8 поскольку по табличке выше видно, что код юниты отсортированы лексикографически (правда не понятно зачем этот факт может быть полезен, ведь это не лексикографисечкая сортировка конкретного языка, в виду разбросанности его букв по таблице код поинтов, но ладно)

А для UTF-16 очевидно, a_cp < b_cp не связанно с a_utf-16 < b_utf-16 

Дальше начинается мем.
```
Å  // А с кружочком сверху
```
Сколько это код поинтов? В Юникоде есть три способа это записать, я заебусь это гуглить, поэтому словестное описание, представьте сами как это выглядит:
1. 1 код поинт: латинская заглавная буква А с кружком сверху (там небольшой пробел между ними)
2. 2 код поинта: латинская заглавная буква А и кружок сверху
3. 1 код поинт: А с кружком сверху (без пробела, там даже есть умное название)

Вывод какой? Что это треш..

С иерогливами там вообще пиздец непонятно как это склеивать, если ты конечно не владелец языка.

Стоит писать программу, не думаю о том как оно будет выведено на экран, ведь в кодировках поддерживается, что внутри одного чара не найдется другой, поэтому все алгоритмы будут корректны.

Про перевод из заглавных в строчные. Говорят, что для ютф-16 функцию to_lower_case() норм писать, а для ютф-8 нет. Но это тоже не совсем правда, потому что это связь строчной и заглавной определяется языком. А в греческом вообще сигма в середине и в конце слова выглядят по разному. Поэтому капитализация слова невозможна в целом, без алфавита и правил языка.

Еще мем: в греческом есть слово "штрассе", где "cc" (осуждаю) это символ эсцет, строчными он выглядит как русская "в", а закглавными, внимание, "SS".

Там еще пара приколов в лекции но я это писать не буду, у меня русско-английская клавиатура, sorry.

Какой из этого всего можно сделать вывод?
1. не пытаться думать о том как буквы представлены
2. если все таки это надо все знать, то соболезнуем всем селом, и желаем долгих лет жизни. Но на вашу радость существует UTF-8 manifest, пропогандирующий повсеместное использование его. Но винда написана на 16-битных чарах, Qt тоже. Им просто поебать, не хочется все переписывать на 8-битные. Но винда все таки после долгих просьб добавили поддержку utf-8.
3. ту сам ап, используйте ютф-8 чтобы не было больно, особенно если вы не кроссплатформенные

А что у нас по именам файлов?
На линуксе валидное любое имя, не содержащее слэша и нулевого символа. На винде есть свои ограничение. Важно понимать, что не любая валидная строчка может быть валидным именем файла.

Следующий мем. На винде названия файлов кейс-устойчивые, т.е. "foo" и "FOO" это один и тот же файл. А как они это делают? При форматирование диска записывается его таблица капитализации. Это прям свойство диска. 

Мораль всего этого: не надо говорить, что юникод плохой или криво сделан. Он сделать криво в меру кривоты человеческих языков.

А эможди в свою очередь очень мотивируют юникод, т.к. его теперь почти все программы поддерживают :)

Существует "неразрывный пробел нулевой длинны". Винда использует его, чтобы определять кодировку файла, но он однозначен только для ютф-8

                                                                    
                                                                    
                                                                    
                                                                    
# Lecture 10. Концепты 1

Фича С++20

Мотивация: банальный пример с vector, он шаблонный по типу Т, однако на этот тип есть строгие ограничения, например, что он не может быть функцией или сылкой, должен уметь муваться. Тогда возникает желание уметь это описывать средствами языка, а не заходом в стандарт или на сппреференс.
```
template <typename T>  // если хотим, чтобы Т был разрушаемым, то в С++20 можно написать:
// template <destructible T>
struct vector {
    
};
```
Какие бонусы от этого?
1. Ошибки компиляции
Если передать ссылку в качестве Т, то получишь около 100 строк лога ошибки компиляции, а если передать не дестрактибл тип, то его поймают статик_ассертом и, как следствие, сообщение об ошибке не будет выглядеть ужасающе. Или, например, сортировка листа. Она невозможна, т.к. у листа итераторы не random-access. Вот хотелось бы возможность прописывать такие общие требования к параметрам класса, чтобы сообщения об ошибках не выглядели так пиздово.
2. Иногда нужно, чтоюы функция применялась только для конкретного множетсва типов 
    * std::max для comparable
    * vector<T>::assign иммет несколько перегрузок:
        - ```void assign(size_t n, T const& value)```
        -   ```
            template <typename It> // requires is_iterator_v<It> (С++20)
            void assign(It first, It last);
            ```
        Но если мы делаем vector<size_t> и вызываем v.assign(10, 42), то что вызывать? Вообще кажется, что амбиг, но варианты на самом деле (size_t, size_t) и (int, int), и второй приоритетнее. Но она внутри не скомпилируется, т.к. int это не итератор. Понятно, что человек когда это писал, рассчитывал на первую перегрузку. В std для решения таких проблем с ограничениями на тип It прописывают enable_if. Но это как-то не прямое решение, она тяжелая для использования и понимания.
        + через SFINAE оказывается дольше компилируется.
        + через SFINAE лог ошибки выглядит страшно (за исключением некоторых компиляторов)

Есть еще минусы у SFINAE: допустим, мы хотим различать предикаты A, B, C, которые B in A, C in B:
```
A
A && B
A && B && C
```
И если писать функции, то такое будет корректно, т.к. всегда сможет найтись более специализированный вариант, и мы не пишем какой-то вспомогательный код:
```
void f(A const&);
void f(B const&);
void f(C const&);
```
Но если это писать как предикат на типы, то это выглядит так:
```
A<T> && !B<T>
A<T> && B<T> && !C<T>
A<T> && B<T> && C<T>
```
И это не только вопрос сложности, но и масштабируемости тоже (при добавлении нового предиката, подмножетсва предыдушего, надо все сигнатуры менятть :/ )

Еще пример:
```
template <typename It>
void advance(It& iter, ptrdiff_t n); // iter += n без требования О(1)
```

Хочется иметь две перегрузки:
1. random access за O(1)
2. не random access за O(n)

Вариантов как это сделать много, но самый прямолинейный -- это с концептами.

Концепты круче if constexpr (С++17):
1. сразу отсекается вариант, что функция не скомпилируется внутри (SFINAE-friendly)
2. if constexpr не дает возможность расширить функцию

Почему концепты не выражаются через наследование от другого типа?
- это требование интрузивное
- концептуализировать стд будет сложно, там нигде нет намека на такое требование (даже Страуструп писал об этом)
- сложно мастабировать предикать на n типов
    ```
    template <typename C, typename It>
    void erase(C&, It cosnt&);
    // тут конечно можно так, но идеологически этот пример наталкивает на тезис
    template <typename C>
    void erase(C&, typename <C>::iterator cosnt&);
    ```

Концепты == "типы типов"
Вообще вся стандартная библиотека формулировалась в терминах концептов, просто не было инструмента, позволяющего это реализовать

Немного истории, отвечающей на вопросы "а почему не сделали так?"
1. С++98
    Первая мысль о концептах, тогда появились шабоны и неймспейсы. Но шаблоны сами по себе были сложны и для юзеров и для разрабтчиков компиляторов. Решили, что пока не будут усложнять. Все равно все ошибки детектятся, да в момент подстановки, но детектятся. 
    
2. С++11
    Первый пропозл концептов. Существовал прямо до выхода релиза. Был даже компилятор ConceptGCC, но в последний момент после статьи Стауструпа его убрали. Беспокойства: **explicit vs. implicit** концепты. Достаточно ли написать деструктор, этого достаточно чтобы соответствовать концепту destructible или надо явно это написать? Изначально было все explicit но со временем появлялось все больше implicit. + за explicit, что иногда просто не понятно из окружения, удовлетворяет он или нет. (input vs forward iterator)
    Второй момент -- **definition checking**. И некоторые его проблемы:
    ```
    template <ordered T>
    T const& min(T const& a, T const& b) {
        return a < b ? a : b;
    }
    ```
    Здесь ordered можно проверять не только типы аргументов, которые переданв, но и тело функции, что в нем мы пользуемся только запрошенными требованиями. (тут пример про объявление функций в Си)
    * ConceptGCC работал долго и это было так, потому что он делал это definition checking, а значит такое нельзя выпускать как официальный компилятор.
    * Если захочется залогировать в какой-то момент значение, то для того, чтобы вывести его в стрим, придется прописывать реквайерсы на вывод во все функции в стеке, опять же из-за дефенишн чекинга. Можно сейчас через if constexpr это решить, но это C++17 :)
    * понятия dependent type, name (когда проверка в момент подстановки) не применимы тогда к Т, т.к. они проверяться должны, а в языке есть одновременно два вида функций с и без дефинишен чекинга. Тогда если из старых новые вызываем -- все ок, проверится. Но если из новых вызываем старые -- проблема, что делать? 
        + не заходить туда, но это странно
        + подставлять и формально чекать
        
        но к консенсусу как-то не пришли.
    
    **Concept map**
    Мэппинг концепта для какого-то типа в соответвующие требования дргугого (ex: стек требует push pop, у вектора их нет, но можно как бы сопоставить push ~> push_back, pop ~> pop_back) (ex: T* это итератор с value_type = T)
    С ними была следующие приколы: простой с точки зрения человека код не сходился по типам, потому что компилятор не видел явно прописанного ```concept C1 : C2 {}```. 
    
    Еще одна проблема была со сложнотсью реализации проверки предиката: ```predicat(*it)``` выполняется как проверка возможности разыменования итереатора, потом просмотр его value_type, проверка, может ли predicat скушать value_type. Чем длинне цепочка, тем сложнее и явнее надо это все прописывать.
    
    Концептуализация стандартной библиотеки. Из (a < b) можно получить любую другую из 6 стандартных. Поэтому они начали дробить концепты, чтобы не сломать большинство пользовательского кода (т.к. есть классы где люди писали только оператор<, например). И, кажется, дробить концепты -- не тот вектор, куда двигаться нужно. В итоге сейчас требуется реализовывать все 6 операций.
    
    
    
    
    
# Lecture 11. Концепты 2

3. С++17
    Пропозл концептов. В нем нет понятия explicit concept. Его поведение можно проэмулировать через constexpr bool переменную. И там нет дефинишн чекинга, поскольку это основная проблема была и в 11 версии. Концепт мапы там тоже нет, но даже в стд это обходится через внешние и внутренние функции, где внешняя вызывает внутреннюю, которую можно переопределить (например, begin() у массива).
    
    Почему не вошли в релиз?
    * Они были недостаточно опробованы. Был только ConceptGCC, а других компиляторов и не было
    * В стд не было концептов
    * auto немного конфликтовало с синтаксисом концептов (некоторые из коротких записей концептов не вошли и в 20 стандарт поэтому)
    * Неуверенность, что definition checking реализуем в таком виде
    
4. С++20
    Finnaly happened.
    
```
template <typename T>
concept destructible = std::id_no_throw_destructible<T>;  // any bool expression
```

Как этим пользоваться?
```
template <typename T>
requires destructible<T>
void f(T&);
```

Есть короткая форма:
```
template <destructible T>
void f(T&);
```

Или:
```
void f(destructible auto&);
```

Во втором варианте записи синтаксис работает по такому принципу:
```
template <A, B, C, D, E>
concept X = ...;

template <X A> <~> template <X<B, C, E, D> A>
```

Очень частное явление, что сразу появляется и полная и короткая записи, потому что, когда люди привыкнут, они захотят иметь короткую форму, и, чтобы не ныли блять несколько пропозлов, она появляется сразу.

А зачем в третьем варианта auto?
Запись ```template <C x>``` можно прочитать как:
* 
    ```
    template <typename x>
    requires C<x>
    ```
*
    ```
    template <auto x>
    requires C<x>
    ```
    
Чтобы такой путаницы не было, этим штукам соответствуют следующие записи:
*
    ```
    template <C x>
    ```
*
    ```
    template<C auto x>
    ```
    
Спецификация **requires-expression**
```
template <typename T>
concept comparable = requires(T a) {
    {a < a} /* noexcept */ -> std::convertible_to<bool>; // но это плохой концепт, тут 1 из 6 операций только
    {a < a} /* noexcept */ -> std::same_as<bool>; // эквивалентно
}
```

Reqirenment'ы бывают 4 типов:
1. Валидность выражения (begin(a))
2. Type requirenment (typename T::value_type)
3. Compaund requirenment (как в примере)
4. Nest requirenments (requires C<T> -- тоже посчитать концепт и если он тру, мы тру)

Как собственно этим пользоваться, для маркировки перегрузок?
```
void advance(input_iterator auto&, find_if_t);
void advance(random_access_iterator auto&, ptrdiff_t)
```
Рандом-аксес более специализирован, поэтому хочется чтобы выбирался он, а не было амбига. В стандарте прописано, как [сравнивать концепты](https://en.cppreference.com/w/cpp/language/constraints)

Если вкратце, выражение парсится с игнорированием скобок, запоминанием мест конъюнкции (&&) и дизъюнкции (||), раскрытием вызова других концептов. Все что не это, то есть atomic constraint, с ним ничего не делают, оставляют как есть. (тут что-то с матлогикой связано, скоро увидим) Дальше строятся СДНФ и СКНФ и проверяют наличие парных клозов.

Тут начинаются приколы.

Если дописать ```&& true```, то станет более специалиированным, т.к. он не будет смотреть внутрь тру, это атомик констраинт. Более того разные true, это разные атомик констреинты.

Мораль: не надо писать хуйню в реквайер блоке, там надо список концептов перечислить.

Как написать **std::same_as<T>**?

```
template <typename T, typename U>
concept same_as = std::is_same_t<T, U>;
// этого недосаточно, т.к. same_as<T, U> и same_as<U, T> это не одно и то же.

template <typename T, typename U>
concept same_as = std::is_same_t<T, U> && std::is_same_t<U, T>;
// лучше, но тоже неправильно, потому что это разные атомик констреинты до сих пор

template <typename T, typename U>
concept is_same_as_t = std::is_same_t<T, U>;

template <typename T, typename U>
concept same_as = is_same_as_t<T, U> && is_same_as_t<U, T>;
// теперь норм
```

Рассказ про то как концепты упрощают жизнь при написаниии SFINAE-friendly классов, таких как std::pair и std::optional, можно посмотреть [тут](https://www.youtube.com/watch?v=vYzjV0xSqJE). Нотесов не будет.

Какие бенефиты имеются с этой языковой конструкции?
* Возможность явно писать документацию
* Успрощает ошибки компиляции (избавились от всего стека инстанцирования, но часто ошибки концептов приводят к ошибке перегрузки :/ )
* Эта техника сильно проще SFINAE
* Компилируется быстрее чем SFINAE
* Можно адекватным объемом кода перегружать шаблонные функции (когда одна более специализированне другой)

Что по поддержке компиляторов? Все крупные поддерживают.

requires на шаблонной функции можно написать как после template <typename> так и после объявления функции, и вроде как эти случаи эквивалентны.


    
    
    
# Lecture 12. Ranges

Тема, связанная с концептами, тоже появилась как расширение стандартной библиотеки в С++20. Изначально это разрабатывалось как std2.

Мотивация:
```
vector<int> v;
sort(v.begin(), v.end());
```
А почему для сорта передаем итераторы?
1. Можно сортить промежуток
2. Можно сортить по реверс итераторам

Хочется иметь что-то в духе ```sort(v)``` в качестве шорт ката для сортировки всего контейнера. Но тогда надо качественно ограничивать (концептами, например) то, что передать можно в сорт.

Еще момент, что в стд есть множетсво реализованных простых алгоритмов, и существует мнение, что писать такие функции > писать сырые форы.

Пример: парсинг .m3u файлов (это плейлист, просто список файлов, допустимы комментарии и абсолютные пути). Тогда можно подойти традиционным методом парсинга: разбить на токены и обрабатывать. Но можно подойти следующим образаом, построив типо пайплайна:
1. возьмем файл
2. разобъем по '\n'
3. из каждой строки срежем комментарии
4. каждую потримим
5. отфильтровать пустые строки
6. для каждой строки скомбинировать ее с текущим каталогом

Понятно, что это псевдокод, но можно и в список функции превратить. Заметим, что убедиться в корректности данного кода проще, чем в корректности стандартного парсинга. То есть понятно, какие эффекты будут получены если поменять какие-то шаги данного алгоритма. Но это не агитация так всегда писать, а показателььный пример.

Может показаться, что при реализации такого алгоритма будет множется лишних аллокации на строчки на каждом шаге. Но можно обойтись и без этого. Сделать для контейнера его view-контейнер, обращаясь к которому, тот будет выдывать ожидаемые данные из исходного контейнера. (ex: работать с развернутом вектором -- [i] ~> [size() - 1 - i], begin() ~> --rend()). Вью идет как бы жадно, например, для сплита строки необязательно сплитить всю строку, можно дойти до первого вхождения '\n' и вернуть собранную строку, при следующей запросе -- аналогично далее.

Концепция вьюх оказывается расширяемой, и при наличии нужного количества вьюх (split(2), transform(3, 4), filter(5), transpose(6)), можем реализовать наш алгоритм без дополнительный аллокаций. 

[Unix pipe примерно так и работает на константной памяти (но не везде, например, на сорте не получится, очевидно)]

В С++20 в дополнение к обычным алгоритмам сделали пачку вьюх и можно сделать пайплайн прямо в плюсах. ахуеть.

Мотивационный пример:
```
total = accumulate(iota(1)
    | transform([](int x) {return x + x;} 
    | take(10), 0);
```
Почти С++20 код, т.к. нет рэнжовой версии accumulate.

В стандарт вошла часть библиотеки ranges v3, та, которая не вызывала никаких вопросов.

Мысль, что итераторы не нужны, а рэнжи вместо них -- прикольно.

А **что**, собвственно, **такое range**? Есть три дизайн-варианта:
1. D-like ranges

    Хранит набор элементов, которые еще не просмотрели, есть функции типо достать первый/последний. То есть они сужаемые.
    Проблема: а как выдавать позицию?
    В D есть семейство функций-аналогов std::find (find, findSkip, findSlit, findSplitAuto, findSplitBefore), которые возвращают рэнжи, полученные из исходного сплитом по каким-то правилам. Не очень красиво конечно, но жить можно.
    Еще сложно передавать аргументы туда (пример: partial_sort от трех итераторов, где сортировка происходит по элементам [it1, it3), так чтобы [it1, it2) были отсортированы, удачи в рэнжах выражать это)
    
2. Position-based ranges

    Как итератор, но ссылается на элемент и требует знания контейнера для обращения к этому элементу.
    Какие плюсы?
        * всегда есть контейнер, проще проверять валидность рэнжа
        * исключение вопросов, связанных со временем жизни, т.к. там всегда контейнер передается
    Минусы?
        * вводится новый объект, а все написано на итераторах
3. range is pair of iterators

    Почти все библиотеки построены на этом, поэтому и в С++20 это так.

```
vector<int> v;
auto rng = views::reverse(v);
```
Должен ли этот rng держать v по ссылке или честно его скопировать в себя?
В С++20 есть два фундаментальных понятия:
1. **range** - все что имеет begin и end **но только lvalue**
2. **view** - range & movable in O(1) (надо пометить класс constexpr bool **enable_view** = true)

Тогда:
1. Если приходит рэнж, то сохраняем ссылку
2. Если приходит вью, то копируем в себя 

**Как ослабили требования на итераторы**: раньше требовали для чтобы у контейнера были begin и end, причем одного типа, для условного вектора это само собой разумеется, но если например есть istream_iterator, то его end это по сути заглушка, которая сообщает что она end, поскольку по инпуту мы бежим только слева направо. А это не слишком эффективно. Теперь разрешили бегин и энд быть разными типами. Такой энд называют sentinel -- он либо итератор, либо специальный тип, умеющий сравниваться на предмет достижения конца диапазона. Даже существует класс unreachable_sentinel.

Рэнжи, у которых тип бегина совпадает с эндом называются **common range**. Если нало из не-коммон рэнжа получить коммон, есть специальная вьюха, которая это делает. 

**Переосмыслили категории итераторов**: раньше было требование, что разыменование итератора должно возващать ссылку на элемент, это ок, пока не пришли вьюхи, поскольку у них ссылку не вернуть, ведь они возвращают новое значение. Более того, будучи только форвард итератором, внутри вьюхи можно организовать поведение рандом аксес итератора.

Люди хотели пофиксить это штуку давно, в итоге В БУСТЕ придумали разделение категории на две подкатегории -- **triversal** (то как итератор ходит по диапазону) и **access** (то как обращается). Так, input и output объединились в singlepass итератор, а доступ у итератором стал типо read/write.

В С++20 не стали разделять на трайверсал и аксес, но скзали, что категория тепепрь относится только к трайверсалу, то есть не влияет на доступ. + добавили трайверсал категорию contigouos (элементы лежат в памяти непрерывном блоком). И появился iterator_concept -- про возможности доступа, часто сильнее, чем итератор_катигори.

Все алгоритмы стд были адптированы на рэнжи путем пегерузок от итераторов и рэнжей. В некоторых поменялись ретурн типы. Например, если если у инпут итератора энд был сентенелом, то возможно помимо оутпут итератора юзеру модет понадобиться и место, где в инпуте освободились.

```
copy(v, backinserter(u));  // (1)
copy(f(v), backinserter(u));  // (2)
```
В случае (1) можем вернуть из копи пару итераторов: v.end(), bi.end(). А что, если в качестве вектора v пришел rvalue (2)? Норм кейс, юзер может и не хотеть получать итератор на конец, если передается туда rvalue. тогда вернется пара dangling, bi.end(). Где **dangling** обозначает "здесь бы был ваш итератор, но он протух, sorry".

**Borrowed range** -- рэнж, не владеющий своими итераторами, для него фактически не нужно возвращать данглинг, если он rvalue (ex: stream_view). Отмечается аналогично enable_view через enable_borrowed_view

To sum up:
* В стд вошла далеко не полная верся ranges v3, там всего 17 вьюх имеется. И выход рэнжей приурочен к выходу концептов
* Отсутствует множество полезных штук, по типу "а теперь преобразуй результат в std::vector", проблемы с join^
* Все функции лежать в трех местах, например transform:
    - std::transform -- стандартный привычный
    - std::ranges::transform -- новый крутой молодежный со всеми нудными перегрузками (algorithm)
    - std::ranges::views::transform -- (adapter) - он возвращает созданную вьюху
    - std::ranges::transform_view -- (view) собственно, вьюха


    
    
    
# Lecture 13. Многопоточность 1

На третьем курсе будет курс многопоточности аж целый год, тут будет самый базовый рассказ с прикладными штуками. + Он полезен для рассказа про корутины.

Мотивация: процессоры имеют > 1 ядра зачастую, поэтому можем использовать больше ресурсов процессора, используя многопоточные програмы. (это не единственный способ, можно и запустить несколько копий программы, компиляторы, например, так делают) Но существуют блокирующие операции (чтение стрима), которые будут стопить производительность программы, пока она стоит ждет ввода данных.

**Поток** -- примитива ОС, говорящая процессору, что вот есть еще одна последоваельность комманд, которую можно поисполнять.

Как создать поток?
```
#include <thread>
#include <iostream>

int main() {
    std::thread th([] {
        std::cout << "Hello world!\n";
    });
    
    th.join();
}
```

На функции join() основной поток ждет, когда th завершится.

Можно ли без join()?
1. Мы можем завершиться реньше, чем th что-то выведет
2. Мы не сказали что thread делает в деструкторе. Поток модет находить в двух состояниях:

    * Ассоцироваться с исполняемым потоком
    * Не соотвествовать исполняемому 

    join() -- прекращает эту ассоциацию.
    Если поток сейчас ассоциирован, а у него вызывается деструктор, то проислодит std::terminate.
    Поэтому до вызода из скоупа нужно вызвать одну из двух функций:
    
    * join() -- дождаться завершения потока
    * detach() -- оставить поток болтаться на процессоре 
    
    Но насколько безопасно делать detach()?
    Не очень. Если мы используем глобальные переменные, то гг, у них вызываются деструкторы и мы не сможем обратиться к ним. std::cout -- это глобальная переменная. Механизм исключений в gcc тоже содержит глобальные переменные, поэтому мы теряем возможность try-catch блоки писать.

    При detach() мы теряем возможность контролировать поток, а это грустно :( (теоритически, конечно мы можем так делать, если он ничего опасного не делает, но хз)

Чем отличаются потоки от процессов? Процессы иммеют разную память, птоки внутри процесса -- общую память => когда умирает процесс, умирают и его потоки.

По дефолту делать detach в деструкторе не безопасно. join может быть опасно делать по примерно следующей причине: если поток используется чтобы скидывать на него какую-то работу с возможностью сказать ему стоп, то простой join без сообщения "давай выходи" может привести к бесконечному провисанию.

**std::jthread** (C++20) -- join в деструкторе с коммандой  выхода.

Почему нет функции принудительно кильнуть поток? В ОС это есть, но в плюсы это не вынесено.
Потому что мы не знаем, в каком состоянии находится поток при килле. Так как могут быть не освобожденые ресурсы локальных переменных. Да и общее состояние программы непонятное останется, если сет например балансировался и его килльнули в этот момент. В каком он состоянии? Та же история с аллокаторами, которые используют внутри себя СД.

А процессы нормально килять потому что они не шарят память, и ОС все разгребет сама.

Как работать с потоками? (псевдокод)
Банковское приложенние со счетами клиентов
```
std::array<int32_t, 100'000> accounts;

void transfer(size_t from, size_t to, int32_t ammount) {
    if (accounts[from] < amount) { // (1)
        throw std::runtime_error("no such money in account");
    }
    accounts[from] -= amount;
    account[to] += amount;
}
```
Если много потоков, то проверка (1) не будет корректной, если два потока сразу будут на ней, то мы сможем уйти в минус. Это называтеся **race condition**. Или если в одном потоке заканчиваются вычисления, а в другом примерно в это же время происходит cancell. Что считать правильным: что вычисления закончены, а канселл нажато в пустоту или не завершать вычисления?

Что с этим делать? Добавить, например, флаг -- мьютех (MUTual EXclusion)
mutex.lock() -- лочит, если не залочен, иначе просто ждет пока не разлочится.
mutex.unlock() -- просто анлочит.
```
std::mutex m;
std::array<int32_t, 100'000> accounts;

void transfer(size_t from, size_t to, int32_t ammount) {
    m.lock();
    if (accounts[from] < amount) { // (1)
        throw std::runtime_error("no such money in account");
    }
    accounts[from] -= amount;
    account[to] += amount;
    m.lock();
}
```
Но это бред, если кинется исключение, то никогда не разлочится мютекс. Решение -- РАИИ класс с анлоком в деструкторе.

```
std::mutex m;
std::array<int32_t, 100'000> accounts;

void transfer(size_t from, size_t to, int32_t ammount) {
    std::lock_guard lock(m); 
    if (accounts[from] < amount) {
        throw std::runtime_error("no such money in account");
    }
    accounts[from] -= amount;
    account[to] += amount;
}
```

Но поскольку под мьютексом код выполняется одновременно только в одной секции, то может получиться, что несмотря на множется потоков, код исполняется как при одном.

**Закон Амдала** -- про ускорение работы программы от числа ядер.
Пусть: 1 (объем работы) = p (параллельная часть) + s (последовательная часть)
Тогда T(n) = p / n + s

Мьютекс -- особенность данных, а не функций!

Как можно добиться лучшего параллелизма? Помним, что Мьютекс примерно 40Байт, и просто для каждого инта ебашить по мьютексу дороговато. Но можно вцелом.

```
struct account {
    std::mutex m;
    int32_t balance;
};

std::array<account, 100'000> accounts;

void transfer(size_t from, size_t to, int32_t ammount) {
    if (from == to) {
        return;
    }
    lock_guard lock_from(accounts[from].m);
    lock_guard lock_to(accounts[to].m);
    if (accounts[from].balance < amount) {
        throw std::runtime_error("no such money in account");
    }
    accounts[from].balance -= amount;
    account[to].balance += amount;
}
```

Если будет перевод 1->2 и 2->1, то будет **deadlock** (взаисное ожидание). Можно пофиксить, исполнением меньшего (а почему?).

Определить дедлок можно через граф, где вершины -- мьютексы, ребра -- существование потоков, в которых держа мьютекс u можно залочить мьютекс v;

Можно решить и путем std::lock, который позволяет залочить n мьютексов без возникновения дедлока, вместо отдельных локов на from и to. Вроде он это делает через try_lock() у мьютекса, которая возвращает true если может залочить и false иначе, делайте чо хотите.

Еще пример.
Сделаем очередь, с которой можно работать из разных потоков.
```
template <typename T>
struct concerent_queue {
  
  void push(T val) {
      lock_quard lock(m);
      q.push_back(move(val));
  }
  
  bool empty() {
      lock_guard lock(m);
      return q.empty();
  }
  
  T pop() {
    lock_guard lock(m);
    T val = q.front();
    q.pop_front();
    return val;
  }
  
private:
  std::mutex m;
  std::deque<T> q;
};
```

Оно корректно, но безполезно, т.к. empty() ничего не говорит о состоянии очереди, поскольку как только она что-то вернула и отпустила мьютекс, с очередью может что угодно произойти. Тогда следующий код не корректен:
```
concurent_queue<int> q;
...
while (!q.empty()) {
    q.pop();
}
```

Этот пример показывает, что недостаточно просто все операции обернуть в локи, поскольку они могут ломаться при взаимодействии друг с другом.

Можно написать ```optional<T> try_pop()```, чтобы код выше работал.

```
template <typename T>
struct concerent_queue {
  
  void push(T val) {
    lock_quard lock(m);
    q.push_back(move(val));
  }
  
  optianal<T> try_pop() {
    lock_quard lock(m);
    if (q.empty()) {
      return nullopt;
    }
    T val = q.front();
    q.pop_front();
    return val;
  }
  
private:
  std::mutex m;
  std::deque<T> q;
};
```

А что если хотим, чтобы при пустой очереди поток ждал, пока в ней что-то появится и как-то потом работал с этим? (типо очереди на операции всех потоков к нашей конкурент_кью) Можно бесконечно крутиться в while, но это значит, что мы просто жрем ядро на кручение.

Есть класс, позволяющий ждать -- **std::condition_variable** (способ усыпить поток и потом разбудить его):
* wait
* notify_one
* notufy_all

Кривой код:
```
template <typename T>
struct concerent_queue {
  
  void push(T val) {
    lock_quard lock(m);
    q.push_back(move(val));
    cv.notify_all();
  }
  
  T pop() {
    lock_guard lock(m);
    if (q.empty()) {
        cv.wait();
        // но тут лок остается и как бы бррр
    }
    T val = q.front();
    q.pop_front();
    return val;
  }
  
  optianal<T> try_pop() {
    lock_quard lock(m);
    if (q.empty()) {
      return nullopt;
    }
    T val = q.front();
    q.pop_front();
    return val;
  }
  
private:
  std::mutex m;
  std::conditional_variable cv;
  std::deque<T> q;
};
```
Фикс: (unique_lock -- пара из мьютекса и була, залочен ли он)
```
template <typename T>
struct concerent_queue {
  
  void push(T val) {
    lock_quard lock(m);
    q.push_back(move(val));
    cv.notify_one(); // tandaling heart problem?? зачем пробуждать все, если они опять уснут и просто потратят время на пробуждение/сон
  }
  
  T pop() {
    unique_lock lock(m);
    while (q.empty()) { // но тут недостаточно просто ифа, т.к. после нотифая помеж произойти поп и гг поэтому while
        lock.unlock();  // (2)
        cv.wait();
        lock.lock();
        // это кстати не компилируется
    }
    T val = q.front();
    q.pop_front();
    return val;
  }
  
  optianal<T> try_pop() {
    lock_quard lock(m);
    if (q.empty()) {
      return nullopt;
    }
    T val = q.front();
    q.pop_front();
    return val;
  }
  
private:
  std::mutex m;
  std::conditional_variable cv;
  std::deque<T> q;
};
```
Причем даже если тут был бы один консьюмер, то надо писать while, поскольку кондишн вариаблы могут спонтанно пробудить поток по своему жеданию :| 

Эта штука может все равно криво работать: после строки (2) в поп мы не успели зайти в wait и пришла пачка пушей, тем самым все нотифаи ушли в пустату, а в поп мы думаем что очередь пустая и вэйтимся. Как решать? wait на самом деле принимает в себя лок и делает то, что мы описали:

```
template <typename T>
struct concerent_queue {
  
  void push(T val) {
    {
        lock_quard lock(m);
        q.push_back(move(val));
    }
    cv.notify_one();
  }
  
  T pop() {
    unique_lock lock(m);
    while (q.empty()) {
        cv.wait(lock);
    }
    T val = q.front();
    q.pop_front();
    return val;
  }
  
  optianal<T> try_pop() {
    lock_quard lock(m);
    if (q.empty()) {
      return nullopt;
    }
    T val = q.front();
    q.pop_front();
    return val;
  }
  
private:
  std::mutex m;
  std::conditional_variable cv;
  std::deque<T> q;
};
```

Получили что-то ближе к работающему. Можно даже добавить скоуп, чтобы нотифай делать не под мьютексом, потому что он умеренно дорогой. Но по этой же причине нотифаить нам выгодно только если кто-то ждет, что если добавим бул флаг на это?


```
template <typename T>
struct concerent_queue {
  
  void push(T val) {
    bool was_empty;
    {
        lock_quard lock(m);
        was_empty = q.empty();
        q.push_back(move(val));
    }
    if (was_empty) {
        cv.notify_one();
    }
  }
  
  T pop() {
    unique_lock lock(m);
    while (q.empty()) {
        cv.wait(lock);
    }
    T val = q.front();
    q.pop_front();
    return val;
  }
  
  optianal<T> try_pop() {
    lock_quard lock(m);
    if (q.empty()) {
      return nullopt;
    }
    T val = q.front();
    q.pop_front();
    return val;
  }
  
private:
  std::mutex m;
  std::conditional_variable cv;
  std::deque<T> q;
};
```
Будет мем, поскольку если в поп ждут куча потоков в пустой очереди и приходит куча пушей одновременно, то они пробудят только один поп. Тогда можно вернуть notify_all(). Но тут не очень понятно, что лучше делать на практике.





# Lecture 14. Многопоточность 2

Есть все таки прикол. Пусть есть куча потоков, которые пушат, и куча потоков, которые попают. Пусть пуш происходит быстре чем поп, тогда наша очередь будет анбуанд расти. Кейс вполне реальный, если вспомнить пайп в юниксовом шелле. Тогда давайте добавим чиселку max_size -- характеристику очереди.

Как тогда переписать? У нас есть условие ожидание -- наличие элементов. Тогда надо добавить условие ожидания -- пустота очереди.

```
template <typename T>
struct concerent_queue {
  
  void push(T val) {
    unique_lock lock(m);
    while (q.size() == max_size) {
        has_empty_space.wait(lock);
    }
    q.push_back(val);
    lock.unlock();
    has_some_elements.notify_one();
  }
  
  T pop() {
    unique_lock lock(m);
    while (q.empty()) {
        has_some_elements.wait(lock);
    }
    T val = q.front();
    q.pop_front();
    lock.unlock();
    has_empty_space.notify_one();
    return val;
  }
  
  optianal<T> try_pop() {
    lock_quard lock(m);
    if (q.empty()) {
      return nullopt;
    }
    T val = q.front();
    q.pop_front();
    return val;
  }
  
private:
  size_t const max_size;
  std::mutex m;
  std::conditional_variable has_some_elements;
  std::conditional_variable has_empty_space;
  std::deque<T> q;
};
```

Получили почти симметричные пуш и поп. Пример, чтобы не забывать об этом. + Показывает, что мьютекс и кондишн вариабл не одно и тоже.

Как это все внутри устроено?

Абсолютная дичь, которую не стоит делать:

1. Крутиться в цикле ;/
2. std::this_thread_yield() -- поисполняй кого-то другого

    Переносить поток на другое ядро -- дорого, и скедулер старается так делать как можно реже, поэтому сделав йилд (извини) мы можем получить обратно на это же ядро этот же поток, потому что ядро ОС решили что мигрировать поток дорого.
    
    А зачем эта фунция вообще нужна? Если мы realtime поток с приоритетом 99, то нас скедулер не может выкинуть, пока мы сами не уснем. И тут может захотелься делить работу. Тогда да, тогда норм такое использовать. Один хуй, когда таким позаниматься нам представится непонятно.
    
А как тогда делать? Говорить ОС не то что тебе нечего делать. а что ты что-то ждешь и это сообщить: futex в линуксе -- ОС знает, чего ты ждешь. В glibc есть pthread, в нем лежит std::mutex и использует как раз мьютексы ОС.

Но в нашем примере мы забираем мьютекс на полторы операции. Есть и другой подход -- **spinlock** -- перед тем как заснуть, немного покрутиться в цикле, вдруг дождемся, иначе уснуть. Понятно, что это эвристика. Их обычно делают не через тупой цикл, а через комманду pause.

Вернемся к примеру с банком. Это сплошной UB, поскольку для контейнеров и встроенных типов по правилам С++ нельзя работать с ними одновременно из >1 потока, если возможно одновременно в одном потоке запись, а во втором -- чтение или запись. 

Почему тогда не доопределить это типы чтобы многопоточно с ними работать?
* На самом деле, гарантии разных архитектур относительно переупорядочивания комманд чтения/записи. И не получится требовать от всех одни гарантии + мы замедлим однопоточные программы.
* Того, как сейчас хранятся данные, может быть недостаточно для работы с ними **атомарно** -- неделимо, так что другие потоки не видят промежуточных операций. Часто архитектуры требуют специльные моменты для атомарной работы (типо выравнивая, например [что?]) 
* для операций с интами компилятор делает кучу оптимизаций, окторые могут мешать атомарности работы

Поэтомы для атомарной работы есть класс **std::atomic<T>**, имеющий весь набор операций типа Т +:
* exchange(T) -- записать новое, прочитать старое атомарно
* compare_exchange(T old, T new) -- если актуальное значение == old, то записать new, вернуть true; иначе сказать sorry, обновить old в актуальное, вернуть false

Перепишем банк без мьютексов:
```
std::array<std::atomic<int32_t>, 100'000> accounts;

void transfer(size_t from, size_t to, int32_t ammount) {
    if (from == to) {
        return;
    }
    
    int32_t tmp = accounts[from];
    
    do {
        if (tmp < amount) {
            throw std::runtime_error("no such money in account");
        }
    while (!accounts[from].compare_exchange_weak(tmp, tmp - amount));
    
    account[to] += amount;  // самое простое, потому что атомарно
}
```

**В чем разница compare_exchange_weak/compare_exchange_strong?**
В большинстве архитектур это одни и те же инструкции, но они могут внезапно фейлиться, если даже там актуальное занчение. Поэтому **strong** крутится в цикле пока фейлится, тем самым не фейлясь в итоге, а **weak** -- это как раз то что вызывает стронг. Поскольку мы сами крутимся тут в цикле нам норм использовать вик. 

Атомики сложно устроены, на курсе многопоточности расскажут почему, лучше написать мьютексы и если в профиле не понравится, то пробовать переписать на атомики.


Замечания по атомикам:
* У них тривиал дефолтный конструктор, поэтом у них надо явно инициалзировать и не через {}. В С++20 это поменялось.
* Атомик и неатомик типы могут транслироваться в одинаковые инструкции, но писать неатомик вместо атомика нельзя, т.к.:
    - это ты посмотрел под одну арзитекруту
    - компилятор может оптимизировать неатомик :)

Про **volatile** (никогда не писать) он не связан с многопоточностью^.
* device memory -- если отмэпили какое-то устройство, то чтение/запись в него это дать команду драйверу. Это не соответствует представлению компилятора, что если в ячейку подряд записали 2 и 3, можно сразу писать 3. Вот volatile ему и говорит, что каждая запись и чтение имеет смысл
* UNIX-signals. Обработчик сигнала может вызваться в любой момент, и если хочешь обращаться к переменной внутри сигнала, надо ее делать volatile
* setjmp/longjmp. Можно думать как о goto, который пересекает границы функций, можно как об исключениях в Си. Из setjmp можно выйти второй раз при longjmp. volatile чтобы прееменные при этом сохраняли корректно свое значение, поскольку компилятор не оченб ожидает, что вы дважды будете выходить из функции


**Чем отличаются atomic и volatile?**
*
    ```
    int* p;
    *p = 42;
    *p = 43;
    ```
    Можно ли не делать запись 42?
    Для volatile p нет, а для atomic p можно, поскольку раньше список значений, к которым был готов код был {0, 42, 43}, значит и к {0, 43} он будет готов.
    
*
    ```
    int* p;
    atomic/volatile int* q;
    *p = 10;
    *q = 20;
    ```
    
    Можно ли переупорядочить записи? (p != q)
    Для volatile можно, т.к. оно с интами в нашей памяти никак не взаимодействует, для atomic нельзя -- пусть p := result, q := result_is_ready.
    
Вообще volatile это квалификатор, как и const (cv-quilifier это как раз про const/volatile)

В стд есть куча других видов мьютексов (в бусте еще больше): 
* рекурсивный мьютекс
* мьютекс с таймаутом
* шаред мьютекс -- разделяет риды и врайты так что риды одновременно могут читать, но если есть врайт то они стоят

Если пишешь многопоточную программу, есть thread_sanitizer (работает аналогично address_sanitizer). Есть статичные анализаторы -- в кланге это thread safity analyze.

